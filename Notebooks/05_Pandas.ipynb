{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "name": "Pandas_Manipulation_de_donnees.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "id": "82562f02",
      "cell_type": "markdown",
      "source": "\n# üêº Pandas ‚Äî Manipulation de donn√©es\n_Master IA-GI ‚Äî Notebook 6_\n\nCe notebook suit votre support **Pandas** et va en profondeur : structures (`Series`, `DataFrame`), E/S, s√©lection, nettoyage, agr√©gations, jointures, reshape (pivot/melt), temps & fen√™tres, performance, stylisation, et export.  \nExemples concrets, **exercices avec hints/solutions**, et **mini‚Äëprojet** de bout en bout.\n\n**Objectifs d‚Äôapprentissage**\n- Charger, inspecter, nettoyer et transformer des donn√©es de mani√®re idiomatique\n- S√©lectionner efficacement (`loc`, `iloc`, masques), typer et convertir (`astype`, `to_datetime`)\n- R√©sumer (`groupby`, `agg`, `pivot_table`), reshaper (`melt`, `stack/unstack`), fusionner (`merge/join`)\n- Travailler avec **dates**, **fen√™tres mobiles**, **cat√©gorielles** et **cha√Ænes**\n- Optimiser (vectorisation, `categorical`, `chunksize`) et exporter proprement\n\n**Pr√©-requis** : NumPy, Matplotlib, notions de fichiers CSV/JSON/Excel  \n**Dur√©e estim√©e** : 3‚Äì4h\n",
      "metadata": {}
    },
    {
      "id": "bd43da91",
      "cell_type": "markdown",
      "source": "\n---\n## 0) ‚öôÔ∏è Pr√©paration\n",
      "metadata": {}
    },
    {
      "id": "3a28046e",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nprint(\"Pandas:\", pd.__version__)\nrng = np.random.default_rng(42)\n\n# Options d'affichage utiles\npd.set_option(\"display.max_rows\", 12)\npd.set_option(\"display.max_columns\", 20)\npd.set_option(\"display.width\", 120)\n",
      "outputs": []
    },
    {
      "id": "2852f03f",
      "cell_type": "markdown",
      "source": "\n---\n## 1) Structures de base : `Series` & `DataFrame`\n",
      "metadata": {}
    },
    {
      "id": "5192df46",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\ns = pd.Series([10, 20, 30], index=[\"a\",\"b\",\"c\"], name=\"score\")\ndf = pd.DataFrame({\"name\":[\"Ali\",\"Sara\",\"Yasmin\"], \"age\":[21,23,22], \"grade\":[14.5,16.0,12.0]})\ns, df\n",
      "outputs": []
    },
    {
      "id": "8260ba8a",
      "cell_type": "markdown",
      "source": "\n**√Ä retenir**\n- `Series` = 1D (valeurs + index) ; `DataFrame` = 2D (colonnes nomm√©es + index)\n- `df.info()`, `df.dtypes`, `df.shape`, `df.head()`, `df.describe()`\n",
      "metadata": {}
    },
    {
      "id": "cdb17f67",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\ndf.info()\ndf.describe(include=\"all\")\n",
      "outputs": []
    },
    {
      "id": "7c6bdd76",
      "cell_type": "markdown",
      "source": "\n---\n## 2) Entr√©e/Sortie & typage\n- `read_csv`, `read_json`, `read_excel` ; `to_csv`, `to_json`, `to_excel`\n- Conversion de types : `astype`, `to_numeric`, `to_datetime`, `Categorical`\n",
      "metadata": {}
    },
    {
      "id": "c800732b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\n# CSV jouet\ndf.to_csv(\"students.csv\", index=False)\ndf_csv = pd.read_csv(\"students.csv\")\n# JSON\ndf.to_json(\"students.json\", orient=\"records\", force_ascii=False)\ndf_json = pd.read_json(\"students.json\")\n\n# Typage\ndf_csv[\"age\"] = df_csv[\"age\"].astype(\"int64\")\ndf_csv[\"grade\"] = pd.to_numeric(df_csv[\"grade\"], errors=\"coerce\")\ndf_csv.dtypes, df_json.head(3)\n",
      "outputs": []
    },
    {
      "id": "9776c746",
      "cell_type": "markdown",
      "source": "\n**Exercice 2.1 ‚Äî Datetime & cat√©gorielles**  \nCr√©e un DataFrame `sales` avec colonnes `date` (cha√Æne), `product` (str), `qty` (int). Convertis `date` en `datetime64[ns]` et `product` en `category` ordonn√© par fr√©quence d√©croissante.\n\n<details>\n<summary>üí° Hint</summary>\n`pd.to_datetime`, `value_counts().index`, `astype(pd.CategoricalDtype(categories=..., ordered=True))`\n</details>\n<details>\n<summary>‚úÖ Solution</summary>\n\n```python\nsales = pd.DataFrame({\n    \"date\": [\"2025-01-02\",\"2025-01-05\",\"2025-02-10\",\"2025-01-02\",\"2025-03-01\"],\n    \"product\": [\"A\",\"B\",\"A\",\"C\",\"B\"],\n    \"qty\": [3,2,4,1,5]\n})\nsales[\"date\"] = pd.to_datetime(sales[\"date\"])\norder = sales[\"product\"].value_counts().index\ncat = pd.api.types.CategoricalDtype(categories=order, ordered=True)\nsales[\"product\"] = sales[\"product\"].astype(cat)\nsales.dtypes, sales.head()\n```\n</details>\n",
      "metadata": {}
    },
    {
      "id": "0dea4f5f",
      "cell_type": "markdown",
      "source": "\n---\n## 3) S√©lection & indexation : `loc`, `iloc`, masques\n",
      "metadata": {}
    },
    {
      "id": "c606f84d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nstudents = pd.DataFrame({\n    \"name\": [\"Ali\",\"Sara\",\"Yasmin\",\"Youssef\",\"Aya\"],\n    \"age\": [21, 23, 22, 24, 22],\n    \"grade\": [14.5, 16.0, 12.0, 13.0, 16.0],\n    \"city\": [\"F√®s\",\"Mekn√®s\",\"Khouribga\",\"Rabat\",\"Casablanca\"]\n}).set_index(\"name\")\n\n# loc/iloc\nsubset_label = students.loc[[\"Sara\",\"Aya\"], [\"age\",\"grade\"]]\nsubset_pos = students.iloc[1:4, 0:2]\nmask = (students[\"grade\"] >= 14) & (students[\"age\"] <= 23)\nfiltered = students[mask]\nsubset_label, subset_pos, filtered\n",
      "outputs": []
    },
    {
      "id": "4f1da675",
      "cell_type": "markdown",
      "source": "\n**Bonnes pratiques**\n- Pr√©f√©rer `loc`/`iloc` plut√¥t que `[]` ambigu\n- Cha√Ænage d‚Äôindexation √† √©viter : utiliser `.loc[mask, \"col\"] = ...`\n",
      "metadata": {}
    },
    {
      "id": "b3fa3af3",
      "cell_type": "markdown",
      "source": "\n---\n## 4) Nettoyage & pr√©paration\n- Valeurs manquantes : `isna`, `fillna`, `dropna`\n- Cha√Ænes : `.str.strip().lower().replace(...)`, regex avec `.str.replace(..., regex=True)`\n- Duplicats : `duplicated`, `drop_duplicates`\n- Bornes/outliers : `clip`, `quantile`, `mask`\n",
      "metadata": {}
    },
    {
      "id": "217f7c91",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nraw = pd.DataFrame({\n    \"id\":[1,2,3,3,4],\n    \"city\":[\"  F√®s \",\"MEKN√àS\",\"khouribga\",\"Rabat\",None],\n    \"score\":[10, None, 200, 15, 14]\n})\nclean = raw.copy()\nclean[\"city\"] = (clean[\"city\"]\n                 .fillna(\"unknown\")\n                 .str.strip().str.lower()\n                 .str.normalize(\"NFKD\").str.encode(\"ascii\",\"ignore\").str.decode(\"utf-8\"))\n# Outliers : cap entre 0 et 100\nclean[\"score\"] = pd.to_numeric(clean[\"score\"], errors=\"coerce\").clip(lower=0, upper=100)\nclean = clean.drop_duplicates(subset=[\"id\"])\nraw, clean\n",
      "outputs": []
    },
    {
      "id": "e060f627",
      "cell_type": "markdown",
      "source": "\n**Exercice 4.1 ‚Äî Nettoyage texte**  \nStandardise une colonne `country` en minuscule, sans accents, et remplace toute cha√Æne vide par `NaN` puis impute par `\"n/a\"`.\n\n<details>\n<summary>‚úÖ Solution</summary>\n\n```python\ntmp = pd.DataFrame({\"country\":[\" Maroc \",\"france\",\"\",\"C√îTE D'IVOIRE\",None]})\ntmp[\"country\"] = (tmp[\"country\"].replace(\"\", np.nan)\n                  .str.strip().str.lower()\n                  .str.normalize(\"NFKD\").str.encode(\"ascii\",\"ignore\").str.decode(\"utf-8\")\n                 ).fillna(\"n/a\")\ntmp\n```\n</details>\n",
      "metadata": {}
    },
    {
      "id": "fbdd654e",
      "cell_type": "markdown",
      "source": "\n---\n## 5) Transformations : vectorisation, `apply`, `map`, `assign`, `pipe`\n",
      "metadata": {}
    },
    {
      "id": "d1ce7c74",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\ndfx = students.reset_index().copy()\ndfx[\"passed\"] = dfx[\"grade\"] >= 10\ndfx = dfx.assign(grade2=lambda d: d[\"grade\"]**2)\n\n# map sur s√©ries (ex: bar√®mes)\nbar = {True:\"OK\", False:\"KO\"}\ndfx[\"status\"] = dfx[\"passed\"].map(bar)\n\n# apply sur lignes (√† √©viter si possible, mais utile parfois)\ndef label_row(row):\n    return f\"{row['name']} ({row['city']})\"\ndfx[\"label\"] = dfx.apply(label_row, axis=1)\n\n# pipe pour encha√Æner proprement\ndef norm_minmax(d, col):\n    m, M = d[col].min(), d[col].max()\n    d[col+\"_norm\"] = (d[col]-m)/(M-m)\n    return d\ndfx = (dfx.pipe(norm_minmax, col=\"grade\")\n          .pipe(norm_minmax, col=\"age\"))\n\ndfx.head()\n",
      "outputs": []
    },
    {
      "id": "36e61c4c",
      "cell_type": "markdown",
      "source": "\n---\n## 6) Regrouper, agr√©ger, fen√™trer\n- `groupby(...).agg({...})`, `transform`\n- Fen√™tres mobiles : `rolling`, `expanding`\n- S√©ries temporelles : `resample` (n√©cessite un index datetime)\n",
      "metadata": {}
    },
    {
      "id": "ddf9009c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nsales = pd.DataFrame({\n    \"date\": pd.date_range(\"2025-01-01\", periods=20, freq=\"D\"),\n    \"product\": rng.choice(list(\"ABC\"), size=20),\n    \"qty\": rng.integers(1, 6, size=20),\n    \"price\": rng.normal(100, 10, size=20).round(2)\n})\nsales[\"amount\"] = sales[\"qty\"] * sales[\"price\"]\n\ng = (sales.groupby(\"product\")\n          .agg(qty_sum=(\"qty\",\"sum\"),\n               amount_mean=(\"amount\",\"mean\"),\n               n=(\"qty\",\"size\"))\n          .sort_values(\"qty_sum\", ascending=False))\n\n# Rolling 7 j sur la somme des montants par jour\ndaily = sales.set_index(\"date\").resample(\"D\")[\"amount\"].sum()\nroll = daily.rolling(7, min_periods=1).mean()\ng, daily.head(), roll.head(10)\n",
      "outputs": []
    },
    {
      "id": "5c5a6a42",
      "cell_type": "markdown",
      "source": "\n**Exercice 6.1 ‚Äî Transform**  \nAjoute √† `sales` une colonne `zscore_amount` calcul√©e **par produit** (centr√©e-r√©duite au sein de chaque groupe).\n\n<details>\n<summary>‚úÖ Solution</summary>\n\n```python\ndef zscore(x):\n    return (x - x.mean()) / (x.std(ddof=0) + 1e-12)\nsales[\"zscore_amount\"] = sales.groupby(\"product\")[\"amount\"].transform(zscore)\nsales.head()\n```\n</details>\n",
      "metadata": {}
    },
    {
      "id": "aff36d90",
      "cell_type": "markdown",
      "source": "\n---\n## 7) Fusionner & concat√©ner\n- `pd.merge` (√©quijoin, left/right/outer, cl√©s multiples)\n- `DataFrame.join` (index)\n- `pd.concat` (empiler lignes/colonnes)\n- As-of merges temporels : `pd.merge_asof`\n",
      "metadata": {}
    },
    {
      "id": "d92734f2",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nleft = pd.DataFrame({\"id\":[1,2,3,4], \"city\":[\"fes\",\"rabat\",\"meknes\",\"casa\"]})\nright = pd.DataFrame({\"id\":[1,1,2,5], \"income\":[2000,2100,2500,3000]})\nm1 = pd.merge(left, right, on=\"id\", how=\"left\")\n\n# concat lignes\nextra = pd.DataFrame({\"id\":[6], \"city\":[\"tanger\"], \"income\":[2200]})\nm2 = pd.concat([m1, extra], ignore_index=True)\n\n# merge_asof (appariement par date la plus proche <=)\nticks = pd.DataFrame({\"t\": pd.to_datetime([\"2025-01-01\",\"2025-01-03\",\"2025-01-05\"]),\n                      \"px\":[10, 11, 13]})\ntrades = pd.DataFrame({\"t\": pd.to_datetime([\"2025-01-02\",\"2025-01-04\"]),\n                       \"qty\":[100, 80]})\nasof = pd.merge_asof(trades.sort_values(\"t\"),\n                     ticks.sort_values(\"t\"),\n                     on=\"t\",\n                     direction=\"backward\")\nm1.head(), m2.tail(3), asof\n",
      "outputs": []
    },
    {
      "id": "3ee2f49b",
      "cell_type": "markdown",
      "source": "\n**Exercice 7.1 ‚Äî Cl√©s multiples**  \nFais un `merge` sur `[\"product\",\"date\"]` entre deux DataFrames (`sales` et un `promo` listant des remises par produit/date). Remplis `NaN` de remise par 0 et calcule `amount_net = amount * (1 - discount)`.\n\n<details>\n<summary>‚úÖ Solution</summary>\n\n```python\npromo = pd.DataFrame({\n    \"date\": pd.date_range(\"2025-01-03\", periods=5, freq=\"3D\"),\n    \"product\": [\"A\",\"B\",\"A\",\"C\",\"B\"],\n    \"discount\": [0.10, 0.15, 0.05, 0.20, 0.0]\n})\ntmp = pd.merge(sales, promo, on=[\"product\",\"date\"], how=\"left\")\ntmp[\"discount\"] = tmp[\"discount\"].fillna(0.0)\ntmp[\"amount_net\"] = tmp[\"amount\"] * (1 - tmp[\"discount\"])\ntmp.head()\n```\n</details>\n",
      "metadata": {}
    },
    {
      "id": "0a2d4de7",
      "cell_type": "markdown",
      "source": "\n---\n## 8) Reshape : `pivot`, `melt`, `stack/unstack`, `pivot_table`\n",
      "metadata": {}
    },
    {
      "id": "ec1da2aa",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nwide = sales.pivot_table(index=\"date\", columns=\"product\", values=\"amount\", aggfunc=\"sum\")\nlong = wide.reset_index().melt(id_vars=\"date\", var_name=\"product\", value_name=\"amount\")\nstacked = wide.stack()             # MultiIndex (date, product)\nunstacked = stacked.unstack()      # revient √† wide\nwide.head(), long.head(), stacked.head(3)\n",
      "outputs": []
    },
    {
      "id": "270d2aa1",
      "cell_type": "markdown",
      "source": "\n---\n## 9) Index & `MultiIndex`\n- D√©finir/r√©initialiser l‚Äôindex : `set_index`, `reset_index`\n- MultiIndex pour hi√©rarchies : groupby multi-niveaux, acc√®s `xs`\n",
      "metadata": {}
    },
    {
      "id": "fe0b0e5a",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nmi = (sales.assign(month=lambda d: d[\"date\"].dt.to_period(\"M\").dt.to_timestamp())\n           .set_index([\"month\",\"product\"])\n           .sort_index())\nagg = mi.groupby(level=[\"month\",\"product\"])[\"amount\"].sum()\nxs_A = agg.xs(\"A\", level=\"product\")\nagg.head(6), xs_A.head(3)\n",
      "outputs": []
    },
    {
      "id": "761f495f",
      "cell_type": "markdown",
      "source": "\n---\n## 10) S√©ries temporelles : `resample`, `shift/diff`, fen√™tres\n",
      "metadata": {}
    },
    {
      "id": "6cbe7363",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nts = (sales.set_index(\"date\")\n            .groupby(\"product\")[\"amount\"]\n            .resample(\"W\").sum()\n            .unstack(0))  # colonnes = produits\nma = ts.rolling(2, min_periods=1).mean()\nchg = ts.diff()\nts.head(), ma.head(), chg.head()\n",
      "outputs": []
    },
    {
      "id": "7afd6c8b",
      "cell_type": "markdown",
      "source": "\n---\n## 11) Performance & grands jeux de donn√©es\n- Cat√©gorielles (`astype('category')`) pour colonnes discr√®tes\n- Vectoriser au maximum ; √©viter les `apply` ligne\n- Lecture par morceaux : `read_csv(..., chunksize=10_000)` + `concat`\n",
      "metadata": {}
    },
    {
      "id": "1749a23d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nbig = pd.DataFrame({\n    \"k\": rng.choice(list(\"ABCDEFGHIJ\"), size=50_000),\n    \"v\": rng.normal(0, 1, size=50_000)\n})\nbig_cat = big.assign(k=lambda d: d[\"k\"].astype(\"category\"))\nres = big_cat.groupby(\"k\")[\"v\"].mean().sort_values(ascending=False).head(5)\nbig.memory_usage(deep=True).sum(), big_cat.memory_usage(deep=True).sum(), res\n",
      "outputs": []
    },
    {
      "id": "4f1456a8",
      "cell_type": "markdown",
      "source": "\n---\n## 12) Visualisation rapide (via Matplotlib)\n> Pandas d√©l√®gue √† Matplotlib. Un **graphique par figure** pour respecter les consignes.\n",
      "metadata": {}
    },
    {
      "id": "6da14261",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\ndaily.plot()\nplt.title(\"Montant quotidien (toutes cat√©gories)\")\nplt.xlabel(\"Date\"); plt.ylabel(\"Montant\")\nplt.tight_layout()\n",
      "outputs": []
    },
    {
      "id": "697a6fe9",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nma.plot()\nplt.title(\"Moyenne mobile hebdo (fen√™tre=2)\")\nplt.xlabel(\"Semaine\"); plt.ylabel(\"Montant moyen\")\nplt.tight_layout()\n",
      "outputs": []
    },
    {
      "id": "1e9f1658",
      "cell_type": "markdown",
      "source": "\n---\n## 13) Mise en forme tabulaire & export\n- `DataFrame.style` pour surligner, barre de progression, formats\n- Export : `to_csv`, `to_excel`, `to_json`, `to_parquet` (si install√©)\n",
      "metadata": {}
    },
    {
      "id": "e028bd2c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\ntop = (sales.groupby(\"product\")[\"amount\"]\n             .sum()\n             .sort_values(ascending=False)\n             .rename(\"revenue\"))\n\nstyled = (top.to_frame()\n            .style.format(\"{:,.2f}\")\n            .bar(color=None, vmin=0)  # sans pr√©ciser de couleur\n         )\nstyled\n",
      "outputs": []
    },
    {
      "id": "f53fd9c9",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\n# Exports\nsales.to_csv(\"sales_clean.csv\", index=False)\nwide.to_excel(\"sales_pivot.xlsx\")\n\"Fichiers enregistr√©s: sales_clean.csv, sales_pivot.xlsx\"\n",
      "outputs": []
    },
    {
      "id": "c1f663b2",
      "cell_type": "markdown",
      "source": "\n---\n## 14) üìù Quiz express\n1) Diff√©rence entre `loc` et `iloc` ?  \n2) `groupby(...).transform` vs `agg` ?  \n3) Quand utiliser `merge_asof` ?  \n4) Deux moyens de reshaper de long √† large ?  \n5) Avantages des variables cat√©gorielles ?\n\n<details>\n<summary>‚úÖ Corrig√©</summary>\n\n1) `loc` par **labels** ; `iloc` par **positions**.  \n2) `transform` renvoie un **r√©sultat align√©** sur la taille d‚Äôorigine ; `agg` r√©sume **par groupe**.  \n3) Appariement temporel **par plus proche ‚â§** (timestamps).  \n4) `pivot/pivot_table` et `unstack` (ou `melt` dans l‚Äôautre sens).  \n5) **M√©moire r√©duite**, perfs groupby/tri, ordres logiques garantis.\n</details>\n",
      "metadata": {}
    },
    {
      "id": "91028724",
      "cell_type": "markdown",
      "source": "\n---\n## 15) üéØ Mini‚Äëprojet ‚Äî *Pipeline de donn√©es ‚Äúventes‚Äù complet*\n**Contexte** : Tu disposes de fichiers `sales.csv` (transactions) et `products.csv` (catalogue).  \n**Objectif** : Construire un pipeline **reproductible** : nettoyage ‚ûú enrichissement ‚ûú KPIs ‚ûú reshape ‚ûú s√©ries temporelles ‚ûú export.\n\n**Sp√©cifications**\n1) **Chargement** : simuler `sales.csv` (date, product_id, qty, price) et `products.csv` (product_id, name, category).  \n2) **Nettoyage** : `to_datetime`, outliers sur `price` (clip quantiles 1%‚Äì99%), suppression duplicats.  \n3) **Enrichissement** : `amount = qty*price`, jointure sur `product_id`.  \n4) **KPIs** : par `category` ‚ûú revenu total, panier moyen (`amount/transaction`), top‚ÄëN produits.  \n5) **Reshape** : pivot mensuel `category √ó month` des revenus, plus `rolling(2)` sur la s√©rie globale.  \n6) **Export** : `to_csv` des tables cl√©s + 2 figures Matplotlib (un graphe/figure).\n\n> Tu peux r√©utiliser `pipe`, `assign`, `groupby`, `merge`, `pivot_table`, `resample` et `rolling`.\n",
      "metadata": {}
    },
    {
      "id": "78920c7d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\n# 1) Chargement (simulation)\nrng = np.random.default_rng(123)\nn = 500\ndates = pd.to_datetime(\"2025-01-01\") + pd.to_timedelta(rng.integers(0, 120, n), unit=\"D\")\nproduct_ids = rng.integers(100, 110, n)\nqty = rng.integers(1, 6, n)\nprice = np.round(rng.normal(100, 20, n), 2)\n\nsales = pd.DataFrame({\"date\": dates, \"product_id\": product_ids, \"qty\": qty, \"price\": price})\nproducts = pd.DataFrame({\n    \"product_id\": np.arange(100,110),\n    \"name\": [f\"P{i}\" for i in range(100,110)],\n    \"category\": rng.choice([\"A\",\"B\",\"C\"], size=10)\n})\n\n# 2) Nettoyage\nsales[\"date\"] = pd.to_datetime(sales[\"date\"], errors=\"coerce\")\nq1, q99 = sales[\"price\"].quantile([0.01, 0.99])\nsales[\"price\"] = sales[\"price\"].clip(q1, q99)\nsales = sales.drop_duplicates()\n\n# 3) Enrichissement\nsales[\"amount\"] = sales[\"qty\"] * sales[\"price\"]\nfull = pd.merge(sales, products, on=\"product_id\", how=\"left\")\n\n# 4) KPIs\nrevenue_by_cat = full.groupby(\"category\")[\"amount\"].sum().sort_values(ascending=False)\nbasket = (full.assign(basket=lambda d: d[\"amount\"])  # une ligne = une transaction\n               .groupby(\"category\")[\"basket\"].mean())\n\ntopN = (full.groupby([\"category\",\"name\"])[\"amount\"].sum()\n            .sort_values(ascending=False)\n            .groupby(level=0).head(3)\n            .reset_index())\n\n# 5) Reshape mensuel + rolling\nfull[\"month\"] = full[\"date\"].dt.to_period(\"M\").dt.to_timestamp()\npivot_rev = full.pivot_table(index=\"month\", columns=\"category\", values=\"amount\", aggfunc=\"sum\")\nrev_daily = full.set_index(\"date\")[\"amount\"].resample(\"D\").sum()\nrev_roll = rev_daily.rolling(14, min_periods=1).mean()\n\n# 6) Export tables\nrevenue_by_cat.to_csv(\"kpi_revenue_by_category.csv\")\nbasket.to_csv(\"kpi_basket_by_category.csv\")\npivot_rev.to_csv(\"pivot_month_category_revenue.csv\")\n\n# Figures (Matplotlib, une par figure)\npivot_rev.plot()\nplt.title(\"Revenus mensuels par cat√©gorie\")\nplt.xlabel(\"Mois\"); plt.ylabel(\"Revenu\")\nplt.tight_layout()\nplt.savefig(\"fig_revenue_month_category.png\", dpi=300, bbox_inches=\"tight\")\n\nrev_roll.plot()\nplt.title(\"Revenu quotidien (moyenne mobile 14j)\")\nplt.xlabel(\"Date\"); plt.ylabel(\"Revenu (MM14)\")\nplt.tight_layout()\nplt.savefig(\"fig_revenue_rolling.png\", dpi=300, bbox_inches=\"tight\")\n\n# R√©sum√©\nrevenue_by_cat.head(), basket.head(), topN.head(), pivot_rev.head()\n",
      "outputs": []
    },
    {
      "id": "494dd948",
      "cell_type": "markdown",
      "source": "\n---\n## üìö Ressources\n- Pandas User Guide : https://pandas.pydata.org/docs/user_guide/index.html  \n- Cookbook : https://pandas.pydata.org/docs/user_guide/cookbook.html  \n- Time series : https://pandas.pydata.org/docs/user_guide/timeseries.html  \n- Reshaping : https://pandas.pydata.org/docs/user_guide/reshaping.html  \n",
      "metadata": {}
    }
  ]
}