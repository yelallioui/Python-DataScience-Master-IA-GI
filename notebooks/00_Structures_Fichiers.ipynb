{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "name": "Structures_donnees_et_fichiers.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "id": "0603379e",
      "cell_type": "markdown",
      "source": "\n# ðŸ§© Structures de donnÃ©es & manipulation de fichiers\n_Master IAâ€‘GI â€” Notebook 2_\n\n**Objectifs dâ€™apprentissage**\n- MaÃ®triser les **structures natives** de Python : `list`, `tuple`, `dict`, `set`\n- Savoir choisir la structure adaptÃ©e (mutabilitÃ©, ordre, unicitÃ©)\n- Lire/Ã©crire des fichiers **texte**, **CSV**, **JSON**, (aperÃ§u **Excel**)\n- GÃ©rer les **erreurs dâ€™E/S**, **encodages**, et les **chemins** avec `pathlib`\n- PrÃ©parer le terrain pour **NumPy** et **Pandas**\n\n**PrÃ©â€‘requis** : Notebook 1 (bases Python)  \n**DurÃ©e estimÃ©e** : 2h\n",
      "metadata": {}
    },
    {
      "id": "9f7cd160",
      "cell_type": "markdown",
      "source": "\n---\n## 1) Tour dâ€™horizon des structures natives\n- `list` : sÃ©quence **mutable** et **ordonnÃ©e**\n- `tuple` : sÃ©quence **immuable**\n- `dict` : **mapping** clÃ© â†’ valeur (ordonnÃ© depuis Python 3.7+)\n- `set`  : **ensemble** dâ€™Ã©lÃ©ments **uniques** (non ordonnÃ©)\n\n> RÃ¨gle pratique : *Commence par `list`/`dict`; utilise `tuple` pour figer des donnÃ©es; `set` pour tester l'appartenance rapide et supprimer les doublons.*\n",
      "metadata": {}
    },
    {
      "id": "d77aadf9",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\n# DÃ©monstrations express\ncities = [\"FÃ¨s\", \"MeknÃ¨s\", \"Khouribga\"]\ncoords = (34.0, -5.0)              # tuple = immuable\nstudent = {\"name\": \"Sara\", \"age\": 23, \"grade\": 16.0}\ntags = {\"python\", \"data\", \"python\"} # set supprime les doublons\n\ncities.append(\"Casablanca\")\nstudent[\"age\"] += 1\n\nprint(\"cities:\", cities)\nprint(\"coords:\", coords)\nprint(\"student:\", student)\nprint(\"tags:\", tags)\n",
      "outputs": []
    },
    {
      "id": "8389635d",
      "cell_type": "markdown",
      "source": "\n**Exercice 1.1 â€” Choisir la bonne structure**  \nPour reprÃ©senter chacun des objets suivants, quelle structure choisir ? Pourquoi ?\n1) Une liste d'Ã©tudiants **ordonnÃ©e** par date d'inscription  \n2) Les coordonnÃ©es `(lat, lon)` d'une ville  \n3) Un rÃ©pertoire **sans doublon** de motsâ€‘clÃ©s (tags)  \n4) Un enregistrement Ã©tudiant (nom, Ã¢ge, note)\n\n<details>\n<summary>âœ… Proposition</summary>\n\n1) `list` (ordre important)  \n2) `tuple` (donnÃ©es fixes, immuables)  \n3) `set` (unicitÃ©)  \n4) `dict` (clÃ© â†’ valeur)\n</details>\n",
      "metadata": {}
    },
    {
      "id": "51a66f69",
      "cell_type": "markdown",
      "source": "\n---\n## 2) Listes & comprÃ©hensions\n- OpÃ©rations frÃ©quentes : `append`, `extend`, `insert`, `pop`, `remove`, slicing\n- **ComprÃ©hensions** : concises, rapides, lisibles\n",
      "metadata": {}
    },
    {
      "id": "1777e364",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nnums = [1, 4, 9, 16, 25]\nroots = [n**0.5 for n in nums if n % 2 == 0]  # garder pairs, racines carrÃ©es\nprint(\"roots:\", roots)\n\n# Slicing\nprint(\"slice 1:4 ->\", nums[1:4])\nprint(\"last two ->\", nums[-2:])\n",
      "outputs": []
    },
    {
      "id": "26cc1997",
      "cell_type": "markdown",
      "source": "\n**Exercice 2.1 â€” Nettoyage**  \nÃ€ partir de `raw = [\"  AI  \", \"python\", \"Data  \", \"  science\"]`, crÃ©e une liste nettoyÃ©e :\n- strip des espaces\n- tout en minuscules\n- sans doublons tout en **conservant l'ordre**\n\n<details>\n<summary>ðŸ’¡ Hint</summary>\nUtilise une boucle + `if x not in seen:` avec un `set` *seen*.\n</details>\n\n<details>\n<summary>âœ… Solution</summary>\n\n```python\nraw = [\"  AI  \", \"python\", \"Data  \", \"  science\", \"python\"]\nclean = []\nseen = set()\nfor x in raw:\n    y = x.strip().lower()\n    if y not in seen:\n        seen.add(y)\n        clean.append(y)\nclean\n```\n</details>\n",
      "metadata": {}
    },
    {
      "id": "e38ad563",
      "cell_type": "markdown",
      "source": "\n---\n## 3) Tuples, dictionnaires et sets â€” astuces utiles\n- **Tuple unpacking** : `name, age = (\"Sara\", 23)`\n- **Dict** : `keys()`, `values()`, `items()`, `get`, `setdefault`\n- **Set** : opÃ©rations ensemblistes `| & - ^`\n",
      "metadata": {}
    },
    {
      "id": "d3c6bf90",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nperson = (\"Sara\", 23)\nname, age = person\nprint(f\"{name=} {age=}\")\n\ngrades = {\"Ali\": 14.5, \"Sara\": 16.0, \"Youssouf\": 12.0}\npassed = {k: (v >= 10) for k, v in grades.items()}\nprint(\"passed:\", passed)\n\na = {\"ai\", \"python\", \"ml\"}\nb = {\"python\", \"data\"}\nprint(\"union:\", a | b, \"intersection:\", a & b, \"diff:\", a - b)\n",
      "outputs": []
    },
    {
      "id": "fc78c11f",
      "cell_type": "markdown",
      "source": "\n---\n## 4) Fichiers texte, encodage & chemins (`pathlib`)\n- `Path` pour manipuler des chemins indÃ©pendamment de lâ€™OS\n- Lire/Ã©crire un **fichier texte** (`.write_text`, `.read_text`)\n- **Encodage** : toujours prÃ©ciser `encoding=\"utf-8\"`\n",
      "metadata": {}
    },
    {
      "id": "065d1c03",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom pathlib import Path\n\ndata_dir = Path(\"data\")\ndata_dir.mkdir(exist_ok=True)\n\np = data_dir / \"hello.txt\"\np.write_text(\"Bonjour Data Science ðŸ‘‹\", encoding=\"utf-8\")\ncontent = p.read_text(encoding=\"utf-8\")\nprint(content)\nprint(\"exists?\", p.exists(), \"| size:\", p.stat().st_size, \"bytes\")\n",
      "outputs": []
    },
    {
      "id": "a850eee9",
      "cell_type": "markdown",
      "source": "\n---\n## 5) Lire/Ã‰crire des **CSV** (sans Pandas)\n- Module standard `csv` : robuste, clair\n- `DictWriter` / `DictReader` pour travailler **par colonnes** (noms)\n",
      "metadata": {}
    },
    {
      "id": "9da6705b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nimport csv\nfrom pathlib import Path\n\ncsv_path = Path(\"data\") / \"students.csv\"\nrows = [\n    {\"name\": \"Ali\", \"age\": 21, \"grade\": 14.5},\n    {\"name\": \"Sara\", \"age\": 23, \"grade\": 16.0},\n    {\"name\": \"Youssouf\", \"age\": 20, \"grade\": 12.0},\n]\nwith csv_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n    writer = csv.DictWriter(f, fieldnames=[\"name\", \"age\", \"grade\"])\n    writer.writeheader()\n    writer.writerows(rows)\n\n# Lecture\nwith csv_path.open(encoding=\"utf-8\") as f:\n    reader = csv.DictReader(f)\n    data = list(reader)\n\n# Conversion de types\nfor r in data:\n    r[\"age\"] = int(r[\"age\"])\n    r[\"grade\"] = float(r[\"grade\"])\n\ndata\n",
      "outputs": []
    },
    {
      "id": "1ab9d5f6",
      "cell_type": "markdown",
      "source": "\n**Exercice 5.1 â€” Statistiques depuis CSV**  \nÃ€ partir de `data` (dÃ©jÃ  chargÃ© ciâ€‘dessus), calcule :\n- la **moyenne** des `grade`\n- le **meilleur** Ã©tudiant (par `grade`)\n- le **nombre** de validÃ©s (â‰¥ 10)\n\n<details>\n<summary>âœ… Solution</summary>\n\n```python\ngrades = [r[\"grade\"] for r in data]\nmean = sum(grades)/len(grades)\nbest = max(data, key=lambda r: r[\"grade\"])\npassed = sum(1 for r in data if r[\"grade\"] >= 10)\n(mean, best, passed)\n```\n</details>\n",
      "metadata": {}
    },
    {
      "id": "2ff98352",
      "cell_type": "markdown",
      "source": "\n---\n## 6) Lire/Ã‰crire du **JSON**\n- Format clÃ©â€‘valeur **structurÃ©** (idÃ©al pour Ã©changes API)\n- `json.dump` / `json.load` pour fichiers\n- `json.dumps` / `json.loads` pour chaÃ®nes\n",
      "metadata": {}
    },
    {
      "id": "d50e6898",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nimport json\nfrom pathlib import Path\n\njson_path = Path(\"data\") / \"students.json\"\npayload = {\"students\": data, \"meta\": {\"cohort\": \"IA-GI\", \"year\": 2025}}\n\nwith json_path.open(\"w\", encoding=\"utf-8\") as f:\n    json.dump(payload, f, ensure_ascii=False, indent=2)\n\nwith json_path.open(encoding=\"utf-8\") as f:\n    loaded = json.load(f)\n\nloaded[\"meta\"], len(loaded[\"students\"])\n",
      "outputs": []
    },
    {
      "id": "22c4c0ed",
      "cell_type": "markdown",
      "source": "\n---\n## 7) (Bonus) Ã‰crire un **Excel** simple (openpyxl)\n> AperÃ§u pour montrer la transition vers Pandas (qui facilitera tout Ã§a).\n",
      "metadata": {}
    },
    {
      "id": "7c7fbf96",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\n# Installation lÃ©gÃ¨re si besoin dans Colab\ntry:\n    import openpyxl  # noqa: F401\nexcept Exception:\n    !pip -q install openpyxl\n\nfrom openpyxl import Workbook\nfrom pathlib import Path\n\nxlsx_path = Path(\"data\") / \"students.xlsx\"\nwb = Workbook()\nws = wb.active\nws.title = \"Students\"\nws.append([\"name\", \"age\", \"grade\"])\nfor r in data:\n    ws.append([r[\"name\"], r[\"age\"], r[\"grade\"]])\nwb.save(xlsx_path)\n\nxlsx_path.exists(), xlsx_path.stat().st_size > 0\n",
      "outputs": []
    },
    {
      "id": "788a9d2a",
      "cell_type": "markdown",
      "source": "\n---\n## 8) Erreurs frÃ©quentes & E/S robustes\n- `FileNotFoundError`, `PermissionError`, `UnicodeDecodeError`\n- StratÃ©gie : `try/except`, vÃ©rification `Path.exists()`, encodage explicite\n",
      "metadata": {}
    },
    {
      "id": "081e6af7",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom pathlib import Path\n\ndef safe_read_text(path: Path, encoding=\"utf-8\"):\n    try:\n        return path.read_text(encoding=encoding)\n    except FileNotFoundError:\n        return f\"[ERREUR] Fichier introuvable : {path}\"\n    except UnicodeDecodeError:\n        return \"[ERREUR] ProblÃ¨me d'encodage â€” essayez encoding='latin-1'\"\n\nprint(safe_read_text(Path(\"data/hello.txt\")))\nprint(safe_read_text(Path(\"data/missing.txt\")))\n",
      "outputs": []
    },
    {
      "id": "5a08c3f6",
      "cell_type": "markdown",
      "source": "\n---\n## 9) ðŸŽ¯ Miniâ€‘projet â€” *RÃ©pertoire dâ€™Ã©tudiants*\n**TÃ¢che** : Construire un petit programme en **3 fonctions** :  \n1) `load_students(path_csv)` âžœ retourne une `list[dict]` (conversion types)  \n2) `summarize(students)` âžœ retourne `{\"mean\": ..., \"best\": ..., \"passed\": ..., \"count\": ...}`  \n3) `save_json(report, path_json)` âžœ Ã©crit un rapport JSON (joli format)  \n\n**SpÃ©cifications**\n- EntrÃ©e : `data/students.csv` (dÃ©jÃ  crÃ©Ã© plus haut)\n- Sorties : affichage **et** fichier `data/summary.json`\n- Bonus : ignorer proprement les lignes incomplÃ¨tes\n\n> Objectif : orchestrer `csv`, `json`, `pathlib`, structures natives, comprÃ©hensions.\n",
      "metadata": {}
    },
    {
      "id": "8e77d101",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\nfrom pathlib import Path\nimport csv, json\n\ndef load_students(path_csv: Path):\n    students = []\n    with path_csv.open(encoding=\"utf-8\") as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            try:\n                students.append({\n                    \"name\": row[\"name\"],\n                    \"age\": int(row[\"age\"]),\n                    \"grade\": float(row[\"grade\"]),\n                })\n            except (KeyError, ValueError):\n                # ligne incomplÃ¨te ou invalide\n                continue\n    return students\n\ndef summarize(students):\n    if not students:\n        return {\"mean\": None, \"best\": None, \"passed\": 0, \"count\": 0}\n    grades = [s[\"grade\"] for s in students]\n    best = max(students, key=lambda s: s[\"grade\"])\n    return {\n        \"mean\": sum(grades)/len(grades),\n        \"best\": best,\n        \"passed\": sum(1 for s in students if s[\"grade\"] >= 10),\n        \"count\": len(students),\n    }\n\ndef save_json(report: dict, path_json: Path):\n    with path_json.open(\"w\", encoding=\"utf-8\") as f:\n        json.dump(report, f, ensure_ascii=False, indent=2)\n\n# Run\nbase = Path(\"data\")\nstu = load_students(base / \"students.csv\")\nrep = summarize(stu)\nsave_json(rep, base / \"summary.json\")\nrep, (base / \"summary.json\").exists()\n",
      "outputs": []
    },
    {
      "id": "bed6baa1",
      "cell_type": "markdown",
      "source": "\n---\n## 10) (AperÃ§u) Faire la mÃªme chose avec **Pandas** (2 lignes)\n> *Teaser* du prochain notebook\n",
      "metadata": {}
    },
    {
      "id": "1d931f9d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "\ntry:\n    import pandas as pd  # noqa: F401\nexcept Exception:\n    !pip -q install pandas\n\nimport pandas as pd\ndf = pd.read_csv(\"data/students.csv\")\ndf[\"passed\"] = df[\"grade\"] >= 10\ndf.describe(include=\"all\"), df.sort_values(\"grade\", ascending=False).head(1)\n",
      "outputs": []
    },
    {
      "id": "0c513276",
      "cell_type": "markdown",
      "source": "\n---\n## ðŸ“š Ressources\n- `csv` : https://docs.python.org/3/library/csv.html  \n- `json` : https://docs.python.org/3/library/json.html  \n- `pathlib` : https://docs.python.org/3/library/pathlib.html  \n- `openpyxl` : https://openpyxl.readthedocs.io/  \n\n**Prochain notebook** : **NumPy â€” Calcul scientifique et tableaux**\n",
      "metadata": {}
    }
  ]
}